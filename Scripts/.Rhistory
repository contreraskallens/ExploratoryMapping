#this uses the entropy function in calcEnt to weight the matrices with a log-entropy function#
#ORIGINAL#
cleanData <- calcEnt(freqMatrix) #entropy
cleanData[is.na(cleanData)] <- 0 #replace NA with 0.
#REPLICATION#
repCleanData <- calcEnt(repFreqMatrix)
repCleanData[is.na(repCleanData)] <- 0
##SVD##
#ORIGINAL#
#dimensionality reduction#
wholeMacaroni = svd(cleanData, nu = 150, nv = 150) #partial SVD of 150 dimensions.
row.names(wholeMacaroni$u) <- row.names(cleanData) #puts docIDS in the matrices resulting from SVD.
row.names(wholeMacaroni$v) <- colnames(cleanData)
#REPLICATION#
repofWholeMacaroni = svd(repCleanData, nu = 150, nv = 150)
row.names(repofWholeMacaroni$u) <- row.names(repCleanData)
row.names(repofWholeMacaroni$v) <- colnames(repCleanData)
####GLM Models####
# This part of the script has the GLM models of each theory that attempt to predict the theory belonging of each paper #
## PARAMETERS ##
# Set parameters for the prediction. Min and max number of dimensions are used to control the number of dimensions that are to be used in the construction of the models. The procedure loops through the dimensions resulting from the SVD. Starts at minNumberOfDimensions (default: 3), stops at maxNumberOfDimensions (default: 50). "Method" refers to the data used to build and train the models. With "free", dimensions are selected for how well they predict theory belonging against every theory. With "cluster", the training is stratified to the "most similar" theories; e.g. "computational" is built using the dimensions that best predict computational papers when compared to 'bayesian' and 'connectionist'. "Repeats" is the number of iterations of the predicting process. "Source" controls which data set is to be used: "original" uses the original dataset, "replication" uses the replication data, and "cross" uses the projection of the replication data into the SVD space of the original dataset to predict their theories with the models built with the original dataset. #
minNumberOfDimensions <- 3 #lower boundary of D
maxNumberOfDimensions <- 50 # upper boundary of D
repeats <- 1000 # how many repetitions of prediction should be averaged?
method <- "cluster" # "cluster" or "free".
source <- "original" #"original" or "replication", "cross".
##OBJECTS##
if(source == "original"){
my_catalog <- catalog
my_svd <- wholeMacaroni$u
}
if(source == "replication"){
my_catalog <- repCatalog
my_svd <- repofWholeMacaroni$u
}
if(source == "cross"){
my_catalog <- catalog
cross_catalog <- repCatalog
my_svd <- wholeMacaroni$u
#create matrix for projection and populate#
replicationProjection <- matrix(0, nrow = 964, ncol = 3611)
row.names(replicationProjection) <- row.names(repFreqMatrix)
colnames(replicationProjection) <- colnames(freqMatrix)
sharedWords <- colnames(repFreqMatrix)[which(colnames(repFreqMatrix) %in% colnames(freqMatrix))]
replicationProjection[,sharedWords] <- repFreqMatrix[,sharedWords]
#project replica matrix onto previous svd space#
cross_svd <- replicationProjection %*% ginv(diag(wholeMacaroni$d[1:150]) %*% t(wholeMacaroni$v))
}
bestPredictors <- c()
for (topic in topicList) {
glmOutput = glm(my_catalog$topic==topic~.,data=data.frame(my_svd[,1:80]),family=binomial)
bestPredictors = rbind(bestPredictors,data.frame(topic,(t(sort(glmOutput$coefficients,ind=T,decreasing=T)$ix[1:maxNumberOfDimensions]))))
}
row.names(bestPredictors) <- topicList
topicListClassic <- c(topicList[1], topicList[2], topicList[8]) # topic list of traditional approaches (comp, bayes, conn)
topicListAlt <- setdiff(topicList, topicListClassic)
catalogClassic <- my_catalog[which(my_catalog$topic %in% topicListClassic),]
catalogAlt <- my_catalog[which(my_catalog$topic %in% topicListAlt),]
bestPredictorsClusters <- c()
for (topic in topicListClassic) {
glmOutput = glm(catalogClassic$topic==topic~.,data=data.frame(my_svd[which(my_catalog$topic %in% topicListClassic, arr.ind = T),1:80]),family=binomial)
bestPredictorsClusters = rbind(bestPredictorsClusters,data.frame(topic,(t(sort(glmOutput$coefficients,ind=T,decreasing=T)$ix[1:maxNumberOfDimensions]))))
}
for (topic in topicListAlt) {
glmOutput = glm(catalogAlt$topic==topic~.,data=data.frame(my_svd[which(my_catalog$topic %in% topicListAlt, arr.ind = T),1:80]),family=binomial)
bestPredictorsClusters = rbind(bestPredictorsClusters,data.frame(topic,(t(sort(glmOutput$coefficients,ind=T,decreasing=T)$ix[1:maxNumberOfDimensions]))))
}
row.names(bestPredictorsClusters) <- c(topicListClassic, topicListAlt)
dimensionVec <- c(minNumberOfDimensions:maxNumberOfDimensions)
cl <- makeCluster(8)
stopCluster(cl)
dimension = 5
resultsListModel <- lapply(c(1:repeats), matrix, nrow = 8, ncol = 8)
s = 5
if(method == "free") {
trainingSet = sample(1:nrow(my_svd),600) #not controlled training
predictors <- bestPredictors
}
if(method == "cluster"){
trainingSet <- c() # controlled training set for equal representation of each topic. Stratified sampling.
for(topic in topicList){
trainingSet <- c(trainingSet, sample(which(my_catalog$topic==topic), 60)) #takes indices of each topic
}
predictors <- bestPredictorsClusters    }
if(source == "original" | source == "replication"){
testSet = setdiff(1:nrow(my_svd),trainingSet)
}
if(source == "cross"){
trainingSet <- c(1:(nrow(my_svd)))
testSet <- c(1:(nrow(cross_svd)))
}
predictionResults = c()
for (topic in topicList) {
trainingdata <- data.frame(my_svd[trainingSet,unlist(predictors[topic,2:dimension])])
glmTopic = glm(my_catalog$topic[trainingSet]==topic~., data=trainingdata, family=binomial)
#glmTopic = glm(my_catalog$topic[trainingSet]==topic~., data=data.frame(my_svd[trainingSet,unlist(predictors[topic,2:dimension])]), family=binomial)
if(source == "original" | source == "replication"){
testdata = data.frame(my_svd[testSet,unlist(predictors[topic,2:dimension])])
predicted = predict.glm(glmTopic,newdata=testdata,type="response")
#predicted = predict.glm(glmTopic,newdata=data.frame(my_svd[testSet,unlist(predictors[topic,2:dimension])]),type="response")
predictionResults = cbind(predictionResults,scale(predicted))
}
if(source == "cross"){
predicted = predict.glm(glmTopic,newdata=data.frame(cross_svd[testSet,unlist(predictors[topic,2:dimension])]),type="response")
predictionResults = cbind(predictionResults,scale(predicted))
}
}
predictionResults
getwd
getwd()
#### libraries ####
require("MASS") #used to calculate the projection of new data in old SVD space.
# plotting #
require("reshape2")
require("ggplot2")
require("ggthemes")
require("scales")
# dendrogram tree cutting from https://labs.genetics.ucla.edu/horvath/CoexpressionNetwork/BranchCutting/ #
require("dynamicTreeCut")
require("bio3d")
require("moduleColor")
# paralellization of prediction machine #
require("foreach")
require("doParallel")
####FUNCTIONS####
cosineGen <- function(matrix){
lengthVec <- sqrt(rowSums(matrix * matrix))
tcrossprod(matrix) / (lengthVec %o% lengthVec)
}  #Function that generates the cosine between each row of a matrix.
calcEnt <- function(matrix){
workMatrix <- t(matrix) #transposes for division
a <- workMatrix / rowSums(workMatrix) #generates a probability matrix
b <- 1 + ((rowSums(a * log2(a), na.rm = T)) / log2(dim(matrix)[1])) #calculate entropy (1 + (sum of probability times log2 probability, divided by the total number of documents)).
workMatrix <- log(workMatrix[which(b > 0, arr.ind = T), ] + 1) #log normalizes frequency matrix and deletes 0 entropy ones.
workMatrix <- workMatrix * b[b > 0] #weight log normalized matrix by multiplying terms with entropy higher than 0 by its entropy.
return(t(workMatrix)) #returns original, non-transposed matrix.
} #calculates the entropy of each term of a matrix. Uses formula in Martin & Berry, 2007, "Mathematical foundations behind latent semantic analysis".
compareTheories <- function(matrix, cat){
##doc: takes matrix as the result of an svd(u). populates a pre-allocated list of every topic in external topicList (not generalized yet) with matrices of an "index" of similarity using each dimension (column) in matrix for each topic.
resultList <- lapply(lapply(1:8, matrix, data = 0, nrow = 8, ncol = dim(matrix)[2]), function(x){row.names(x) <- topicList; return(x)}) #pre-allocation of list
cosineAvgsList <- lapply(1:8, matrix, data = 0, nrow = 8, ncol = dim(matrix)[1]) #pre-allocation of second list
names(resultList) <- topicList #name for easy accessing theories
indexMatrix <- matrix(FALSE, nrow = dim(matrix)[1], ncol = 8, dimnames = list(1:dim(matrix)[1], topicList)) #pre-allocates logical matrix
for(topic in topicList){indexMatrix[,topic] <- cat[,2] == topic} #populates logical matrix with a logical mask reflecting catalog$id
docsByTop <- colSums(indexMatrix) #number of documents for each topic
n <- 1 #counter for each dimension
while(n <= dim(matrix)[2]){ #loops through dimensions
database <- matrix[, 1:n] #slices dimensions
if(n == 1){dt <- cbind(database, 0)} #if it has only one dimension, then add a column of 0s to make cosineGen work
database <- cosineGen(dt) #produces a x by x matrix of cosines between each paper.
database[is.na(database)] <- 0 #replaces NA with 0.
meanMatrix <- crossprod(indexMatrix, database) #produces a matrix with the sum of cosines of each paper with each of the topics
meanMatrix <- meanMatrix / docsByTop #produces a matrix with the mean cosine of each paper with each of the topics
cosineAvgsList[[n]] <- meanMatrix #stores the matrix of means in a list with n as index for dimensions used.
meanMatrix <- meanMatrix %*% indexMatrix #produces a vector with the sum of mean cosines for each topic against each topic in dimension n
meanMatrix <- t(meanMatrix) / docsByTop #produces a vector of the means of sums of mean cosines for each topic against each topic in dimension n.
for(topic in topicList){ #loops through topics to populate results of all cosines.
resultList[[topic]][, n] <- meanMatrix[topic,]
}
n = n + 1
}
returnList = list(resultList,cosineAvgsList) #makes list of lists with results and mean cosines
return(returnList) #returns everything
} #function for calculating cosines of the whole matrix. "matrix" is the result of an SVD; "cat" is the catalog to obtain topic information (in this case, catalog$id). Returns a list of two lists: [[1]] is all cosines by paper, [[2]] is a list of matrices of mean distance of each paper with each of the other topics. [[1]][n] and [[2]][n] are the different dimensions resulting from SVD.
plotTopicDiff <- function(topic, resultsList){
workTable <- as.data.frame(melt(resultsList[[1]][[topic]], varnames = c("topic", "dimension"), value.name = "cosine")) #long form for ggplot
plot <- ggplot(data = workTable, aes(x = dimension, y = cosine, color = topic, group = topic)) + theme_solarized(base_size = 14) + theme(axis.text = element_text(colour = "#586e75")) + labs(title = paste("Mean cosine of", x, "papers with other theories and itself across dimensions")) + geom_line() + scale_colour_solarized("red") + geom_point(size = 0.7, shape = 3) + guides(colour = guide_legend(override.aes = list(size=3)))
print(plot)
} #function for plotting the mean distance of every topic with all other topics. "topic" is one of the topics of topicList; "resultsList" is the object that compareTheories() returns.
####RAW DATA AND WORD FREQUENCY####
##ORIGINAL##
#loads files and catalog for original#
freqMatrix <- as.matrix(read.table('document_by_term.txt', sep='\t', header = T))[, -1] #loads the DBT minus one column.
row.names(freqMatrix) <- c(1:nrow(freqMatrix)) #row names with docID
freqMatrix <- freqMatrix[, apply(freqMatrix, 2, function(x){sum(x==0) < 1047})] #removes columns with words that appear in fewer than 5 documents.
freqMatrix <- freqMatrix[which(rowSums(freqMatrix) > 0), ] #eliminates documents with 0 terms after cleanup of terminology
catalog <- read.table('catalog.txt', stringsAsFactors = F, sep = '\t', fill = T, quote = "") #loads catalog
catalog <- catalog[row.names(freqMatrix), ] #catalog also has row names as docID
colnames(catalog) = c('id','topic','year','authors','title','journal','abstract') #variable names for catalog
topicList <- unique(catalog$topic) #list of theories for analysis.
##REPLICATION##
#the same, but for replication documents#
repFreqMatrix <- as.matrix(read.table('rep_document_by_term.txt', sep='\t', header = T, quote = ""))[, -1]
row.names(repFreqMatrix) <- c(1:nrow(repFreqMatrix))
repFreqMatrix <- repFreqMatrix[, apply(repFreqMatrix, 2, function(x){sum(x==0) < 1009})] #removes columns with words that appear in fewer than 5 documents.
repFreqMatrix <- repFreqMatrix[which(rowSums(repFreqMatrix) > 0), ]
repCatalog <- read.table('rep_catalog.txt', stringsAsFactors = F, sep = '\t', fill = T, quote = "")
repCatalog <- repCatalog[row.names(repFreqMatrix), ]
colnames(repCatalog) = c('id','topic','year','authors','title','journal','abstract')
topicList <- unique(repCatalog$topic)
#NULL HYPOTHESIS#
#If you want to test the null hypothesis, change the parameter to T. It randomizes the theory of the papers in the databases.#
nullHyp <- F
if(nullHyp == T ){
catalog$topic <- sample(catalog$topic, length(catalog$topic))
repCatalog$topic <- sample(repCatalog$topic, length(repCatalog$topic))
}
####DATA PROCESSING (Latent Semantic Analysis)####
##ENTROPY##
#this uses the entropy function in calcEnt to weight the matrices with a log-entropy function#
#ORIGINAL#
cleanData <- calcEnt(freqMatrix) #entropy
cleanData[is.na(cleanData)] <- 0 #replace NA with 0.
#REPLICATION#
repCleanData <- calcEnt(repFreqMatrix)
repCleanData[is.na(repCleanData)] <- 0
##SVD##
#ORIGINAL#
#dimensionality reduction#
wholeMacaroni = svd(cleanData, nu = 150, nv = 150) #partial SVD of 150 dimensions.
row.names(wholeMacaroni$u) <- row.names(cleanData) #puts docIDS in the matrices resulting from SVD.
row.names(wholeMacaroni$v) <- colnames(cleanData)
#REPLICATION#
repofWholeMacaroni = svd(repCleanData, nu = 150, nv = 150)
row.names(repofWholeMacaroni$u) <- row.names(repCleanData)
row.names(repofWholeMacaroni$v) <- colnames(repCleanData)
####GLM Models####
# This part of the script has the GLM models of each theory that attempt to predict the theory belonging of each paper #
## PARAMETERS ##
# Set parameters for the prediction. Min and max number of dimensions are used to control the number of dimensions that are to be used in the construction of the models. The procedure loops through the dimensions resulting from the SVD. Starts at minNumberOfDimensions (default: 3), stops at maxNumberOfDimensions (default: 50). "Method" refers to the data used to build and train the models. With "free", dimensions are selected for how well they predict theory belonging against every theory. With "cluster", the training is stratified to the "most similar" theories; e.g. "computational" is built using the dimensions that best predict computational papers when compared to 'bayesian' and 'connectionist'. "Repeats" is the number of iterations of the predicting process. "Source" controls which data set is to be used: "original" uses the original dataset, "replication" uses the replication data, and "cross" uses the projection of the replication data into the SVD space of the original dataset to predict their theories with the models built with the original dataset. #
minNumberOfDimensions <- 3 #lower boundary of D
maxNumberOfDimensions <- 50 # upper boundary of D
repeats <- 1000 # how many repetitions of prediction should be averaged?
method <- "cluster" # "cluster" or "free".
source <- "original" #"original" or "replication", "cross".
if(source == "original"){
my_catalog <- catalog
my_svd <- wholeMacaroni$u
}
if(source == "replication"){
my_catalog <- repCatalog
my_svd <- repofWholeMacaroni$u
}
if(source == "cross"){
my_catalog <- catalog
cross_catalog <- repCatalog
my_svd <- wholeMacaroni$u
replicationProjection <- matrix(0, nrow = 964, ncol = 3611)   #create matrix for projection and populate#
row.names(replicationProjection) <- row.names(repFreqMatrix) #set row names as wholeMacaroni
colnames(replicationProjection) <- colnames(freqMatrix)
sharedWords <- colnames(repFreqMatrix)[which(colnames(repFreqMatrix) %in% colnames(freqMatrix))] # obtain all the shared words between original data and replication data.
replicationProjection[,sharedWords] <- repFreqMatrix[,sharedWords] #build a new DbT that has the documents in replication as rows and the shared words between both datasets as columns.
cross_svd <- replicationProjection %*% ginv(diag(wholeMacaroni$d[1:150]) %*% t(wholeMacaroni$v)) #projects the replication data into the SV  space of the original dataset..
}
bestPredictors <- c()
for (topic in topicList) {
glmOutput = glm(my_catalog$topic==topic~.,data=data.frame(my_svd[,1:80]),family=binomial)
bestPredictors = rbind(bestPredictors,data.frame(topic,(t(sort(glmOutput$coefficients,ind=T,decreasing=T)$ix[1:maxNumberOfDimensions]))))
}
row.names(bestPredictors) <- topicList
topicListClassic <- c(topicList[1], topicList[2], topicList[8]) # topic list of classical cluster.
topicListAlt <- setdiff(topicList, topicListClassic) #topic list of alt cluster.
catalogClassic <- my_catalog[which(my_catalog$topic %in% topicListClassic),] #catalog of classic papers
catalogAlt <- my_catalog[which(my_catalog$topic %in% topicListAlt),] #catalog of alt papers
bestPredictorsClusters <- c()
for (topic in topicListClassic) {
glmOutput = glm(catalogClassic$topic==topic~.,data=data.frame(my_svd[which(my_catalog$topic %in% topicListClassic, arr.ind = T),1:80]),family=binomial)
bestPredictorsClusters = rbind(bestPredictorsClusters,data.frame(topic,(t(sort(glmOutput$coefficients,ind=T,decreasing=T)$ix[1:maxNumberOfDimensions]))))
}
for (topic in topicListAlt) {
glmOutput = glm(catalogAlt$topic==topic~.,data=data.frame(my_svd[which(my_catalog$topic %in% topicListAlt, arr.ind = T),1:80]),family=binomial)
bestPredictorsClusters = rbind(bestPredictorsClusters,data.frame(topic,(t(sort(glmOutput$coefficients,ind=T,decreasing=T)$ix[1:maxNumberOfDimensions]))))
}
row.names(bestPredictorsClusters) <- c(topicListClassic, topicListAlt)
dimensionVec <- c(minNumberOfDimensions:maxNumberOfDimensions)
dimension = 5
s = 5
resultsListModel <- lapply(c(1:repeats), matrix, nrow = 8, ncol = 8) #pre allocate the result list with the number of iterations selected in parameters.
if(method == "free") {
trainingSet = sample(1:nrow(my_svd),600) #not controlled training
predictors <- bestPredictors
}
if(method == "cluster"){
trainingSet <- c() # controlled training set for equal representation of each topic.
for(topic in topicList){
trainingSet <- c(trainingSet, sample(which(my_catalog$topic==topic), 60))
}
predictors <- bestPredictorsClusters    }
if(source == "original" | source == "replication"){ #if the procedure is either predicting original for predicting original, or replication for predicting replication, set the trainingset as the rest of the papers.
testSet = setdiff(1:nrow(my_svd),trainingSet)
}
if(source == "cross"){ #if using original to predict replication, trainingset is original dataset, and testset is replication set.
trainingSet <- c(1:(nrow(my_svd)))
testSet <- c(1:(nrow(cross_svd)))
}
predictionResults = c()
for (topic in topicList) { #loop through the models of each theory
trainingdata <- data.frame(my_svd[trainingSet,unlist(predictors[topic,2:dimension])]) # prepare training data of model by using the dimensions selected as the best predictors for each topic and the documents selected to be training.
glmTopic = glm(my_catalog$topic[trainingSet]==topic~., data=trainingdata, family=binomial) #build the model of the topic.
if(source == "original" | source == "replication"){ #if predicting inside the dataset
testdata = data.frame(my_svd[testSet,unlist(predictors[topic,2:dimension])]) #prepare the data to be predicted
predicted = predict.glm(glmTopic,newdata=testdata,type="response") #store the probability that the paper belongs to the theory being tested
predictionResults = cbind(predictionResults,scale(predicted)) #add to a matrix and scale
}
if(source == "cross"){ #modify procedure above to account for original data being training and replication being test
predicted = predict.glm(glmTopic,newdata=data.frame(cross_svd[testSet,unlist(predictors[topic,2:dimension])]),type="response")
predictionResults = cbind(predictionResults,scale(predicted))
}
}
predictionResults = data.frame(predictionResults)
predictionResults
colnames(predictionResults) = topicList
predictionResults
if(source == "original" | source == "replication"){
predictionResults$topic = my_catalog$topic[testSet] #add a column with the correct theory of each of the papers in the testset
predictionResults$predicted_topic = topicList[max.col(predictionResults[,1:8])] #add a column with the highest prediction of the models for that paper.
resultTable <- t(t(table(predictionResults$topic,predictionResults$predicted_topic) / as.vector(table(my_catalog$topic[testSet])))*100)
}
predictionResults
resultTable
table(predictionResults$topic,predictionResults$predicted_topic)
as.vector(table(my_catalog$topic[testSet]))
t(table(predictionResults$topic,predictionResults$predicted_topic))
resultTable <- table(predictionResults$topic,predictionResults$predicted_topic) / as.vector(table(my_catalog$topic[testSet])))*100
resultTable <- (table(predictionResults$topic,predictionResults$predicted_topic) / as.vector(table(my_catalog$topic[testSet])))*100
resultTable
finalRunTable <- matrix(0, nrow = 8, ncol = 8) ## pre allocated table to avoid dimension errors when summing, when topic is not predicted
row.names(finalRunTable) <- topicList
colnames(finalRunTable) <- topicList
finalRunTable
for(topic in colnames(resultTable)){finalRunTable[, topic] = resultTable[, topic]}
finalRunTable
resultsListModel <- lapply(c(1:repeats), matrix, nrow = 8, ncol = 8) #pre allocate the result list with the number of iterations selected in parameters.
s = 1 #controller for the number of iterations.
while(s <= repeats){ # repeats the process of training-prediction as specified in parameters.
if(method == "free") {
trainingSet = sample(1:nrow(my_svd),600) #not controlled training
predictors <- bestPredictors
}
if(method == "cluster"){
trainingSet <- c() # controlled training set for equal representation of each topic.
for(topic in topicList){
trainingSet <- c(trainingSet, sample(which(my_catalog$topic==topic), 60))
}
predictors <- bestPredictorsClusters    }
if(source == "original" | source == "replication"){ #if the procedure is either predicting original for predicting original, or replication for predicting replication, set the trainingset as the rest of the papers.
testSet = setdiff(1:nrow(my_svd),trainingSet)
}
if(source == "cross"){ #if using original to predict replication, trainingset is original dataset, and testset is replication set.
trainingSet <- c(1:(nrow(my_svd)))
testSet <- c(1:(nrow(cross_svd)))
}
predictionResults = c()
for (topic in topicList) { #loop through the models of each theory
trainingdata <- data.frame(my_svd[trainingSet,unlist(predictors[topic,2:dimension])]) # prepare training data of model by using the dimensions selected as the best predictors for each topic and the documents selected to be training.
glmTopic = glm(my_catalog$topic[trainingSet]==topic~., data=trainingdata, family=binomial) #build the model of the topic.
if(source == "original" | source == "replication"){ #if predicting inside the dataset
testdata = data.frame(my_svd[testSet,unlist(predictors[topic,2:dimension])]) #prepare the data to be predicted
predicted = predict.glm(glmTopic,newdata=testdata,type="response") #store the probability that the paper belongs to the theory being tested
predictionResults = cbind(predictionResults,scale(predicted)) #add to a matrix and scale
}
if(source == "cross"){ #modify procedure above to account for original data being training and replication being test
predicted = predict.glm(glmTopic,newdata=data.frame(cross_svd[testSet,unlist(predictors[topic,2:dimension])]),type="response")
predictionResults = cbind(predictionResults,scale(predicted))
}
}
# the predictions of each theory are aggregated in a matrix. each row of matrix is a document, each column is the probability that it belongs to that theory.
predictionResults = data.frame(predictionResults)
colnames(predictionResults) = topicList
if(source == "original" | source == "replication"){
predictionResults$topic = my_catalog$topic[testSet] #add a column with the correct theory of each of the papers in the testset
predictionResults$predicted_topic = topicList[max.col(predictionResults[,1:8])] #add a column with the highest prediction of the models for that paper.
resultTable <- (table(predictionResults$topic,predictionResults$predicted_topic) / as.vector(table(my_catalog$topic[testSet])))*100 #generates a frequency table of how many times each topic was predicted as each other topic. then, transforms into percentages.
}
if(source == "cross") { #same procedure, but for cross prediction.
predictionResults$topic = cross_catalog$topic[testSet]
predictionResults$predicted_topic = topicList[max.col(predictionResults[,1:8])]
resultTable <- (table(predictionResults$topic,predictionResults$predicted_topic) / as.vector(table(cross_catalog$topic[testSet])))*100
}
resultsListModel[[s]] <- resultTable # store this iteration for final aggregation
if(s %% 100 == 0) {print(paste("repetition number", s))} #UI
s = s + 1
}
resultsListModel
for(matrix in resultsListModel) {
finalPredictionTable <- finalPredictionTable + matrix
}
finalPredictionTable <- matrix(0, nrow = 8, ncol = 8) #pre-allocate final table
for(matrix in resultsListModel) {
finalPredictionTable <- finalPredictionTable + matrix
}
final
finalPredictionTable
finalPredictionTable <- finalPredictionTable / length(resultsListModel)
finalPredictionTable
cl <- makeCluster(8)
registerDoParallel(cl)
listResults <- foreach(dimension=dimensionVec, .verbose = T) %dopar% { #parallelized foreach loop with each dimension. Stored in a list object containing the aggregate matrices of iterations controlled in repeat, for each number of dimensions used.
resultsListModel <- lapply(c(1:repeats), matrix, nrow = 8, ncol = 8) #pre allocate the result list with the number of iterations selected in parameters.
s = 1 #controller for the number of iterations.
while(s <= repeats){ # repeats the process of training-prediction as specified in parameters.
if(method == "free") {
trainingSet = sample(1:nrow(my_svd),600) #not controlled training
predictors <- bestPredictors
}
if(method == "cluster"){
trainingSet <- c() # controlled training set for equal representation of each topic.
for(topic in topicList){
trainingSet <- c(trainingSet, sample(which(my_catalog$topic==topic), 60))
}
predictors <- bestPredictorsClusters    }
if(source == "original" | source == "replication"){ #if the procedure is either predicting original for predicting original, or replication for predicting replication, set the trainingset as the rest of the papers.
testSet = setdiff(1:nrow(my_svd),trainingSet)
}
if(source == "cross"){ #if using original to predict replication, trainingset is original dataset, and testset is replication set.
trainingSet <- c(1:(nrow(my_svd)))
testSet <- c(1:(nrow(cross_svd)))
}
predictionResults = c()
for (topic in topicList) { #loop through the models of each theory
trainingdata <- data.frame(my_svd[trainingSet,unlist(predictors[topic,2:dimension])]) # prepare training data of model by using the dimensions selected as the best predictors for each topic and the documents selected to be training.
glmTopic = glm(my_catalog$topic[trainingSet]==topic~., data=trainingdata, family=binomial) #build the model of the topic.
if(source == "original" | source == "replication"){ #if predicting inside the dataset
testdata = data.frame(my_svd[testSet,unlist(predictors[topic,2:dimension])]) #prepare the data to be predicted
predicted = predict.glm(glmTopic,newdata=testdata,type="response") #store the probability that the paper belongs to the theory being tested
predictionResults = cbind(predictionResults,scale(predicted)) #add to a matrix and scale
}
if(source == "cross"){ #modify procedure above to account for original data being training and replication being test
predicted = predict.glm(glmTopic,newdata=data.frame(cross_svd[testSet,unlist(predictors[topic,2:dimension])]),type="response")
predictionResults = cbind(predictionResults,scale(predicted))
}
}
# the predictions of each theory are aggregated in a matrix. each row of matrix is a document, each column is the probability that it belongs to that theory.
predictionResults = data.frame(predictionResults)
colnames(predictionResults) = topicList
if(source == "original" | source == "replication"){
predictionResults$topic = my_catalog$topic[testSet] #add a column with the correct theory of each of the papers in the testset
predictionResults$predicted_topic = topicList[max.col(predictionResults[,1:8])] #add a column with the highest prediction of the models for that paper.
resultTable <- (table(predictionResults$topic,predictionResults$predicted_topic) / as.vector(table(my_catalog$topic[testSet])))*100 #generates a frequency table of how many times each topic was predicted as each other topic. then, transforms into percentages.
}
if(source == "cross") { #same procedure, but for cross prediction.
predictionResults$topic = cross_catalog$topic[testSet]
predictionResults$predicted_topic = topicList[max.col(predictionResults[,1:8])]
resultTable <- (table(predictionResults$topic,predictionResults$predicted_topic) / as.vector(table(cross_catalog$topic[testSet])))*100
}
resultsListModel[[s]] <- resultTable # store this iteration for final aggregation in list.
if(s %% 100 == 0) {print(paste("repetition number", s))} #UI
s = s + 1
}
#aggregate the results of the iterations#
finalPredictionTable <- matrix(0, nrow = 8, ncol = 8) #pre-allocate final table
#iterate through list of predictions to aggregate the results#
for(matrix in resultsListModel) { # sums every result table resulting from the iterations.
finalPredictionTable <- finalPredictionTable + matrix
}
finalPredictionTable <- finalPredictionTable / length(resultsListModel) #divide by total number of iterations to aggregate
return(finalPredictionTable) #return this table to be added to the list that foreach is constructing,
}
dimensionVec <- c(minNumberOfDimensions:maxNumberOfDimensions)
cl <- makeCluster(4)
registerDoParallel(cl)
listResults <- foreach(dimension=dimensionVec, .verbose = T) %dopar% { #parallelized foreach loop with each dimension. Stored in a list object containing the aggregate matrices of iterations controlled in repeat, for each number of dimensions used.
resultsListModel <- lapply(c(1:repeats), matrix, nrow = 8, ncol = 8) #pre allocate the result list with the number of iterations selected in parameters.
s = 1 #controller for the number of iterations.
while(s <= repeats){ # repeats the process of training-prediction as specified in parameters.
if(method == "free") {
trainingSet = sample(1:nrow(my_svd),600) #not controlled training
predictors <- bestPredictors
}
if(method == "cluster"){
trainingSet <- c() # controlled training set for equal representation of each topic.
for(topic in topicList){
trainingSet <- c(trainingSet, sample(which(my_catalog$topic==topic), 60))
}
predictors <- bestPredictorsClusters    }
if(source == "original" | source == "replication"){ #if the procedure is either predicting original for predicting original, or replication for predicting replication, set the trainingset as the rest of the papers.
testSet = setdiff(1:nrow(my_svd),trainingSet)
}
if(source == "cross"){ #if using original to predict replication, trainingset is original dataset, and testset is replication set.
trainingSet <- c(1:(nrow(my_svd)))
testSet <- c(1:(nrow(cross_svd)))
}
predictionResults = c()
for (topic in topicList) { #loop through the models of each theory
trainingdata <- data.frame(my_svd[trainingSet,unlist(predictors[topic,2:dimension])]) # prepare training data of model by using the dimensions selected as the best predictors for each topic and the documents selected to be training.
glmTopic = glm(my_catalog$topic[trainingSet]==topic~., data=trainingdata, family=binomial) #build the model of the topic.
if(source == "original" | source == "replication"){ #if predicting inside the dataset
testdata = data.frame(my_svd[testSet,unlist(predictors[topic,2:dimension])]) #prepare the data to be predicted
predicted = predict.glm(glmTopic,newdata=testdata,type="response") #store the probability that the paper belongs to the theory being tested
predictionResults = cbind(predictionResults,scale(predicted)) #add to a matrix and scale
}
if(source == "cross"){ #modify procedure above to account for original data being training and replication being test
predicted = predict.glm(glmTopic,newdata=data.frame(cross_svd[testSet,unlist(predictors[topic,2:dimension])]),type="response")
predictionResults = cbind(predictionResults,scale(predicted))
}
}
# the predictions of each theory are aggregated in a matrix. each row of matrix is a document, each column is the probability that it belongs to that theory.
predictionResults = data.frame(predictionResults)
colnames(predictionResults) = topicList
if(source == "original" | source == "replication"){
predictionResults$topic = my_catalog$topic[testSet] #add a column with the correct theory of each of the papers in the testset
predictionResults$predicted_topic = topicList[max.col(predictionResults[,1:8])] #add a column with the highest prediction of the models for that paper.
resultTable <- (table(predictionResults$topic,predictionResults$predicted_topic) / as.vector(table(my_catalog$topic[testSet])))*100 #generates a frequency table of how many times each topic was predicted as each other topic. then, transforms into percentages.
}
if(source == "cross") { #same procedure, but for cross prediction.
predictionResults$topic = cross_catalog$topic[testSet]
predictionResults$predicted_topic = topicList[max.col(predictionResults[,1:8])]
resultTable <- (table(predictionResults$topic,predictionResults$predicted_topic) / as.vector(table(cross_catalog$topic[testSet])))*100
}
resultsListModel[[s]] <- resultTable # store this iteration for final aggregation in list.
if(s %% 100 == 0) {print(paste("repetition number", s))} #UI
s = s + 1
}
#aggregate the results of the iterations#
finalPredictionTable <- matrix(0, nrow = 8, ncol = 8) #pre-allocate final table
#iterate through list of predictions to aggregate the results#
for(matrix in resultsListModel) { # sums every result table resulting from the iterations.
finalPredictionTable <- finalPredictionTable + matrix
}
finalPredictionTable <- finalPredictionTable / length(resultsListModel) #divide by total number of iterations to aggregate
return(finalPredictionTable) #return this table to be added to the list that foreach is constructing,
}
